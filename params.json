{"name":"Exhibitor Mesos Framework","tagline":"Exhibitor on Apache Mesos for reliably running Zookeeper on Mesos","body":"Exhibitor Mesos Framework\r\n======================\r\n\r\nThis is still being developed actively and is not yet alpha. [Open issues here](https://github.com/CiscoCloud/exhibitor-mesos-framework/issues).\r\n\r\n[Prerequisites](#prerequisites)  \r\n* [Environment Configuration](#environment-configuration)  \r\n* [Scheduler Configuration](#scheduler-configuration)  \r\n* [Run the scheduler](#run-the-scheduler)  \r\n* [Quick start](#quick-start)  \r\n\r\n[Typical Operations](#typical-operations)  \r\n* [Running scheduler in Marathon](https://github.com/CiscoCloud/exhibitor-mesos-framework/tree/master/src/marathon)   \r\n* [Changing the location of Zookeeper data](#changing-the-location-of-zookeeper-data)\r\n* [Shutting down framework](#shutting-down-framework)\r\n\r\n[Navigating the CLI](#navigating-the-cli)  \r\n* [Requesting help](#requesting-help)  \r\n* [Adding servers to the cluster](#adding-servers-to-the-cluster)  \r\n* [Configuring servers](#configuring-servers-in-the-cluster)  \r\n* [Starting servers](#starting-servers-in-the-cluster)  \r\n* [Stopping servers](#stopping-servers-in-the-cluster)  \r\n* [Removing servers](#removing-servers-from-the-cluster)  \r\n\r\nPrerequisites\r\n-------------\r\n\r\n* Java 7 (or higher)\r\n* Apache Mesos 0.19 or newer\r\n* Exhibitor Standalone jar file (or `mvn` to build it)\r\n* Zookeeper archive file\r\n\r\nClone and build the project\r\n\r\n    # git clone https://github.com/CiscoCloud/exhibitor-mesos-framework.git\r\n    # cd exhibitor-mesos-framework\r\n    # ./gradlew jar\r\n    \r\nBuild Exhibitor Standalone if necessary (**NOTE**: version built with Gradle may be affected by [this issue](https://github.com/Netflix/exhibitor/issues/235) so we use [Maven build](https://github.com/Netflix/exhibitor/wiki/Building-Exhibitor#maven) in this example):\r\n\r\n    # mkdir tmp-exhibitor && cd tmp-exhibitor\r\n    # wget https://raw.github.com/Netflix/exhibitor/master/exhibitor-standalone/src/main/resources/buildscripts/standalone/maven/pom.xml\r\n    # mvn clean package\r\n    # cp target/exhibitor-*.jar ..\r\n    # cd .. && rm -rf tmp-exhibitor\r\n    \r\nDownload Apache Zookeeper distribution if you don't have one (or place the archive to the working folder):\r\n\r\n    # wget http://apache.cp.if.ua/zookeeper/zookeeper-3.4.6/zookeeper-3.4.6.tar.gz\r\n    \r\nDownload Oracle JDK distribution (or place the archive to the working folder). **NOTE**: please pay attention it MUST be Oracle JDK (not OpenJDK and not JRE) as Exhibitor relies on `jps` calls:\r\n\r\n    # wget --no-check-certificate --no-cookies --header \"Cookie: oraclelicense=accept-securebackup-cookie\" http://download.oracle.com/otn-pub/java/jdk/8u45-b14/jdk-8u45-linux-x64.tar.gz\r\n\r\nEnvironment Configuration\r\n--------------------------\r\n\r\nBefore running `./exhibitor-mesos.sh`, set the location of libmesos:\r\n\r\n    # export MESOS_NATIVE_JAVA_LIBRARY=/usr/local/lib/libmesos.so\r\n\r\nIf the host running scheduler has several IP addresses you may also need to\r\n\r\n    # export LIBPROCESS_IP=<IP_ACCESSIBLE_FROM_MASTER>\r\n\r\nScheduler Configuration\r\n----------------------\r\n\r\nThe scheduler is configured through the command line.\r\n\r\nFollowing options are available:\r\n```\r\nUsage: scheduler [options]\r\n\r\n  -m <value> | --master <value>\r\n        Mesos Master addresses. Required.\r\n  -a <value> | --api <value>\r\n        Binding host:port for http/artifact server. Optional if EM_API env is set.\r\n  -u <value> | --user <value>\r\n        Mesos user. Required.\r\n  --framework-name <value>\r\n        Mesos framework name. Defaults to exhibitor. Optional\r\n  --framework-timeout <value>\r\n        Mesos framework failover timeout. Allows to recover from failure before killing running tasks. Should be a parsable Scala Duration value. Defaults to 30 days. Optional\r\n  --storage <value>\r\n        Storage for cluster state. Examples: file:exhibitor-mesos.json; zk:master:2181/exhibitor-mesos. Defaults to file:exhibitor-mesos.json. Optional.\r\n  --ensemble-modify-retries <value>\r\n        Number of retries to modify (add/remove server) ensemble. Defaults to 60. Optional.\r\n  --ensemble-modify-backoff <value>\r\n        Backoff between retries to modify (add/remove server) ensemble in milliseconds. Defaults to 1000. Optional.\r\n  -d <value> | --debug <value>\r\n        Debug mode. Optional. Defaults to false.\r\n```\r\n\r\nRun the scheduler\r\n-----------------\r\n\r\nStart the Exhibitor scheduler using this command:\r\n\r\n    # ./exhibitor-mesos.sh scheduler --master master:5050 --user root --api http://master:6666\r\n\r\n\r\nQuick start\r\n-----------\r\n\r\nIn order not to pass the API url to each CLI call lets export the URL as follows:\r\n\r\n```\r\n# export EM_API=http://master:6666\r\n```\r\n\r\nFirst lets start 1 Exhibitor with the default settings. Further in the readme you can see how to change these from the defaults.\r\n\r\n```\r\n# ./exhibitor-mesos.sh add 0\r\nAdded servers 0\r\n\r\ncluster:\r\n  server:\r\n    id: 0\r\n    state: Added\r\n    constraints: hostname=unique\r\n    exhibitor config:\r\n    shared config overrides:\r\n    cpu: 0.2\r\n    mem: 256.0\r\n    sharedConfigChangeBackoff: 10000\r\n    port: auto\r\n```\r\n\r\nYou now have a cluster with 1 server that is not started.\r\n\r\n```\r\n# ./exhibitor-mesos.sh status\r\ncluster:\r\n  server:\r\n    id: 0\r\n    state: Added\r\n    constraints: hostname=unique\r\n    exhibitor config:\r\n    shared config overrides:\r\n    cpu: 0.2\r\n    mem: 256.0\r\n    sharedConfigChangeBackoff: 10000\r\n    port: auto\r\n```\r\n\r\nEach server requires some basic configuration.\r\n\r\n```\r\n# ./exhibitor-mesos.sh config 0 --configtype zookeeper --zkconfigconnect 192.168.3.1:2181 --zkconfigzpath /exhibitor/config --zookeeper-install-directory /tmp/zookeeper --zookeeper-data-directory /tmp/zkdata\r\nUpdated configuration for servers 0\r\n\r\ncluster:\r\n  server:\r\n    id: 0\r\n    state: Added\r\n    constraints: hostname=unique\r\n    exhibitor config:\r\n      zkconfigzpath: /exhibitor/config\r\n      zkconfigconnect: 192.168.3.1:2181\r\n      configtype: zookeeper\r\n    shared config overrides:\r\n      zookeeper-install-directory: /tmp/zookeeper\r\n      zookeeper-data-directory: /tmp/zkdata\r\n    cpu: 0.2\r\n    mem: 256.0\r\n    sharedConfigChangeBackoff: 10000\r\n    port: auto\r\n```\r\n\r\nNow lets start the server. This call to CLI will block until the server is actually started but will wait no more than a configured timeout. Timeout can be passed via `--timeout` flag and defaults to `60s`. If a timeout of `0ms` is passed CLI won't wait for servers to start at all and will reply with \"Scheduled servers ...\" message.\r\n\r\n```\r\n# ./exhibitor-mesos.sh start 0 --timeout 30s\r\nStarted servers 0\r\n\r\ncluster:\r\n  server:\r\n    id: 0\r\n    state: Running\r\n    constraints: hostname=unique\r\n    exhibitor config:\r\n      zkconfigzpath: /exhibitor/config\r\n      zkconfigconnect: 192.168.3.1:2181\r\n      configtype: zookeeper\r\n    shared config overrides:\r\n      zookeeper-install-directory: /tmp/zookeeper\r\n      zookeeper-data-directory: /tmp/zkdata\r\n    cpu: 0.2\r\n    mem: 256.0\r\n    sharedConfigChangeBackoff: 10000\r\n    port: auto\r\n```\r\n\r\nNow as we don't know where the server we may ask for the cluster status to see where the endpoint is.\r\n\r\n```\r\n# ./exhibitor-mesos.sh status\r\ncluster:\r\n  server:\r\n    id: 0\r\n    state: Running\r\n    endpoint: http://slave0:31000/exhibitor/v1/ui/index.html\r\n    constraints: hostname=unique\r\n    exhibitor config:\r\n      zkconfigzpath: /exhibitor/config\r\n      zkconfigconnect: 192.168.3.1:2181\r\n      port: 31000\r\n      configtype: zookeeper\r\n    shared config overrides:\r\n      zookeeper-install-directory: /tmp/zookeeper\r\n      zookeeper-data-directory: /tmp/zkdata\r\n    cpu: 0.2\r\n    mem: 256.0\r\n    sharedConfigChangeBackoff: 10000\r\n    port: auto\r\n    exhibitor cluster view:\r\n          [slave0, latent, 0, F]\r\n```\r\n\r\n(NOTE: with `exhibitor cluster view` section you can reason about underlying Exhibitor and Zookeeper ensemble.\r\nSince there is some synchronisation lag in Exhibitor when the node is added/removed, the view of the cluster may \r\nbe different from different nodes, that's why this section is shown under all nodes that are in the RUNNING state)\r\n\r\n\r\nBy now you should have a single Exhibitor instance running. Here's how you stop it:\r\n\r\n```\r\n# ./exhibitor-mesos.sh stop 0\r\nStopped servers 0\r\n```\r\n\r\nIf you want to remove the server from the cluster completely you may skip `stop` step and call `remove` directly (this will call `stop` under the hood anyway):\r\n\r\n```\r\n./exhibitor-mesos.sh remove 0\r\nRemoved servers 0\r\n```\r\n\r\nTypical Operations\r\n===================\r\n\r\nChanging the location of Zookeeper data\r\n---------------------------------------\r\n\r\n```\r\n# ./exhibitor-mesos.sh stop 0\r\nStopped servers 0\r\n\r\n# ./exhibitor-mesos.sh config 0 --zookeeper-data-directory /tmp/exhibitor_zkdata\r\nUpdated configuration for servers 0\r\n\r\ncluster:\r\n  server:\r\n    id: 0\r\n    state: Added\r\n    constraints: hostname=unique\r\n    exhibitor config:\r\n      zkconfigzpath: /exhibitor/config\r\n      zkconfigconnect: 192.168.3.1:2181\r\n      configtype: zookeeper\r\n    shared config overrides:\r\n      zookeeper-install-directory: /tmp/zookeeper\r\n      zookeeper-data-directory: /tmp/exhibitor_zkdata\r\n    cpu: 0.2\r\n    mem: 256.0\r\n    sharedConfigChangeBackoff: 10000\r\n    port: auto\r\n```\r\n\r\nShutting down framework\r\n-----------------------\r\n\r\nWhile the scheduler has a shutdown hook it doesn't actually finish the framework. To shutdown the framework completely (e.g. unregister it in Mesos) you may shoot a `POST` to `/teardown` specifying the framework id to shutdown:\r\n\r\n```\r\n# curl -d frameworkId=20150807-094500-84125888-5050-14187-0005 -X POST http://master:5050/teardown\r\n```\r\n\r\nNavigating the CLI\r\n==================\r\n\r\nRequesting help\r\n---------------\r\n\r\n```\r\n# ./exhibitor-mesos.sh help\r\nUsage: <command>\r\n\r\nCommands:\r\n  help       - print this message.\r\n  help [cmd] - print command-specific help.\r\n  scheduler  - start scheduler.\r\n  status     - print cluster status.\r\n  add        - add servers to cluster.\r\n  config     - configure servers in cluster.\r\n  start      - start servers in cluster.\r\n  stop       - stop servers in cluster.\r\n  remove     - remove servers in cluster.\r\n```\r\n\r\nAdding servers to the cluster\r\n-------------------------------\r\n\r\n```\r\n# ./exhibitor-mesos.sh help add\r\nUsage: add <id> [options]\r\n\r\n  -c <value> | --cpu <value>\r\n        CPUs for server. Optional.\r\n  -m <value> | --mem <value>\r\n        Memory for server. Optional.\r\n  --constraints <value>\r\n        Constraints (hostname=like:master,rack=like:1.*). See below. Defaults to 'hostname=unique'. Optional.\r\n  -b <value> | --configchangebackoff <value>\r\n        Backoff between checks whether the shared configuration changed in milliseconds. Defaults to 10000. Optional.\r\n  -a <value> | --api <value>\r\n        Binding host:port for http/artifact server. Optional if EM_API env is set.\r\n  --port <value>\r\n        Port ranges to accept, when offer is issued. Optional\r\n\r\nconstraint examples:\r\n  like:slave0    - value equals 'slave0'\r\n  unlike:slave0  - value is not equal to 'slave0'\r\n  like:slave.*   - value starts with 'slave'\r\n  unique         - all values are unique\r\n  cluster        - all values are the same\r\n  cluster:slave0 - value equals 'slave0'\r\n  groupBy        - all values are the same\r\n  groupBy:3      - all values are within 3 different groups\r\n```\r\n\r\nConfiguring servers in the cluster\r\n----------------------\r\n\r\n**NOTE**: this section is not final and some configurations may change.\r\n\r\n```\r\n# ../exhibitor-mesos.sh help config\r\nUsage: config <id> [options]\r\n\r\n  -a <value> | --api <value>\r\n        Binding host:port for http/artifact server. Optional if EM_API env is set.\r\n  --configtype <value>\r\n        Config type to use: s3 or zookeeper. Optional.\r\n  --configcheckms <value>\r\n        Period (ms) to check for shared config updates. Optional.\r\n  --defaultconfig <value>\r\n        Full path to a file that contains initial/default values for Exhibitor/ZooKeeper config values. The file is a standard property file. Optional.\r\n  --headingtext <value>\r\n        Extra text to display in UI header. Optional.\r\n  --hostname <value>\r\n        Hostname to use for this JVM. Optional.\r\n  --jquerystyle <value>\r\n        Styling used for the JQuery-based UI. Optional.\r\n  --loglines <value>\r\n        Max lines of logging to keep in memory for display. Default is 1000. Optional.\r\n  --nodemodification <value>\r\n        If true, the Explorer UI will allow nodes to be modified (use with caution). Default is true. Optional.\r\n  --prefspath <value>\r\n        Certain values (such as Control Panel values) are stored in a preferences file. By default, Preferences.userRoot() is used. Optional.\r\n  --servo <value>\r\n        true/false (default is false). If enabled, ZooKeeper will be queried once a minute for its state via the 'mntr' four letter word (this requires ZooKeeper 3.4.x+). Servo will be used to publish this data via JMX. Optional.\r\n  --timeout <value>\r\n        Connection timeout (ms) for ZK connections. Default is 30000. Optional.\r\n  --s3credentials <value>\r\n        Credentials to use for s3backup or s3config. Optional.\r\n  --s3region <value>\r\n        Region for S3 calls (e.g. \"eu-west-1\"). Optional.\r\n  --s3config <value>\r\n        The bucket name and key to store the config (s3credentials may be provided as well). Argument is [bucket name]:[key]. Optional.\r\n  --s3configprefix <value>\r\n        When using AWS S3 shared config files, the prefix to use for values such as locks. Optional.\r\n  --zkconfigconnect <value>\r\n        The initial connection string for ZooKeeper shared config storage. E.g: host1:2181,host2:2181... Optional.\r\n  --zkconfigexhibitorpath <value>\r\n        Used if the ZooKeeper shared config is also running Exhibitor. This is the URI path for the REST call. The default is: /. Optional.\r\n  --zkconfigexhibitorport <value>\r\n        Used if the ZooKeeper shared config is also running Exhibitor. This is the port that Exhibitor is listening on. IMPORTANT: if this value is not set it implies that Exhibitor is not being used on the ZooKeeper shared config. Optional.\r\n  --zkconfigpollms <value>\r\n        The period in ms to check for changes in the config ensemble. The default is: 10000. Optional.\r\n  --zkconfigretry <value>\r\n        The retry values to use in the form sleep-ms:retry-qty. The default is: 1000:3. Optional.\r\n  --zkconfigzpath <value>\r\n        The base ZPath that Exhibitor should use. E.g: /exhibitor/config. Optional.\r\n  --filesystembackup <value>\r\n        If true, enables file system backup of ZooKeeper log files. Optional.\r\n  --s3backup <value>\r\n        If true, enables AWS S3 backup of ZooKeeper log files (s3credentials may be provided as well). Optional.\r\n  --aclid <value>\r\n        Enable ACL for Exhibitor's internal ZooKeeper connection. This sets the ACL's ID. Optional.\r\n  --aclperms <value>\r\n        Enable ACL for Exhibitor's internal ZooKeeper connection. This sets the ACL's Permissions - a comma list of possible permissions. If this isn't specified the permission is set to ALL. Values: read, write, create, delete, admin. Optional.\r\n  --aclscheme <value>\r\n        Enable ACL for Exhibitor's internal ZooKeeper connection. This sets the ACL's Scheme. Optional.\r\n  --log-index-directory <value>\r\n        The directory where indexed Zookeeper logs should be kept. Optional.\r\n  --zookeeper-install-directory <value>\r\n        The directory where the Zookeeper server is installed. Optional.\r\n  --zookeeper-data-directory <value>\r\n        The directory where Zookeeper snapshot data is stored. Optional.\r\n  --zookeeper-log-directory <value>\r\n        The directory where Zookeeper transaction log data is stored. Optional.\r\n  --backup-extra <value>\r\n        Backup extra shared config. Optional.\r\n  --zoo-cfg-extra <value>\r\n        Any additional properties to be added to the zoo.cfg file in form: key1\\\\=value1&key2\\\\=value2. Optional.\r\n  --java-environment <value>\r\n        Script to write as the 'java.env' file which gets executed as a part of Zookeeper start script. Optional.\r\n  --log4j-properties <value>\r\n        Contents of the log4j.properties file. Optional.\r\n  --client-port <value>\r\n        The port that clients use to connect to Zookeeper. Defaults to 2181. Optional.\r\n  --connect-port <value>\r\n        The port that other Zookeeper instances use to connect to Zookeeper. Defaults to 2888. Optional.\r\n  --election-port <value>\r\n        The port that other Zookeeper instances use for election. Defaults to 3888. Optional.\r\n  --check-ms <value>\r\n        The number of milliseconds between live-ness checks on Zookeeper server. Defaults to 30000. Optional.\r\n  --cleanup-period-ms <value>\r\n        The number of milliseconds between Zookeeper log file cleanups. Defaults to 43200000. Optional.\r\n  --cleanup-max-files <value>\r\n        The max number of Zookeeper log files to keep when cleaning up. Defaults to 3. Optional.\r\n  --backup-max-store-ms <value>\r\n        Backup max store ms shared config. Optional.\r\n  --backup-period-ms <value>\r\n        Backup period ms shared config. Optional.\r\n  --port <value>\r\n        Port ranges to accept, when offer is issued. Optional\r\n```\r\n\r\nStarting servers in the cluster\r\n-------------------------------\r\n\r\n```\r\n# ./exhibitor-mesos.sh help start\r\nUsage: start <id> [options]\r\n\r\n  -a <value> | --api <value>\r\n        Binding host:port for http/artifact server. Optional if EM_API env is set.\r\n```\r\n\r\nStopping servers in the cluster\r\n-------------------------------\r\n\r\n```\r\n# ./exhibitor-mesos.sh help stop\r\nUsage: stop <id> [options]\r\n\r\n  -a <value> | --api <value>\r\n        Binding host:port for http/artifact server. Optional if EM_API env is set.\r\n```\r\n\r\nRemoving servers from the cluster\r\n----------------------------------\r\n\r\n```\r\n# ./exhibitor-mesos.sh help remove\r\nUsage: remove <id> [options]\r\n\r\n  -a <value> | --api <value>\r\n        Binding host:port for http/artifact server. Optional if EM_API env is set.\r\n```","google":"","note":"Don't delete this file! It's used internally to help with page regeneration."}